# Information Theory (Short Course)

I delivered a short, six hour version of my 
[Information Theory](/work/comp/2610/) course at Tsinghua University from Nov.
28th to Dec. 2nd, 2014.

## Slides

- [Lecture 1](/bits/info/short-l1.pdf): Overview & Introduction

- [Lecture 2](/bits/info/short-l2.pdf): Key results & inequalities

- [Lecture 3](/bits/info/short-l3.pdf): Some applications to machine learning

## References

The material in lectures 1 and 2 are directly from the longer version of my [Information Theory](/work/comp/2610/) course. The primary reference for almost all that material is MacKay's _[Information Theory, Inference, and Learning Algorithms](http://www.inference.phy.cam.ac.uk/mackay/itila/)_ and, to a lesser extent, Cover & Thomas's _[Elements of Information Theory](http://elementsofinformationtheory.com)_.

Lecture 3 draws on a variety of material, including:

- _[Information, Divergence, and Risk](http://jmlr.csail.mit.edu/papers/v12/reid11a.html)_ (Reid & Williamson, 2011) and references therein for the geometric take on Bayes risk curves.

- Cover & Thomas's _[Elements of Information Theory](http://elementsofinformationtheory.com)_ for the treatment of Fano's inequality.

- _[A Game of Prediction with Expert Advice](http://dl.acm.org/citation.cfm?id=291955)_ (Vovk, 1998) on mixability.

- Ceas-Bianchi & Lugosi's excellent _[Prediction, Learning, and Games](http://homes.di.unimi.it/~cesabian/predbook/)_ book on online learning for the proof of the mixability result.

- _[Entropic Duality and Generalised Mixability](http://arxiv.org/abs/1406.6130)_ (Reid, Frongillo, Williamson, Mehta, 2014) for rewriting the mixability condition in terms of an optimisation.

- _[Convex Foundations for Generalized MaxEnt Models](http://mark.reid.name/bits/pubs/maxent13-convex-gefs.pdf)_ (Frongillo & Reid, 2013) for the section on expressing exponential families in terms of convex conjugates.

- There are a number of papers worth exploring [here](http://www.cs.huji.ac.il/labs/learning/Papers/IBM_list.html) on the information bottleneck method that I briefly mentioned at the end of the last lecture.

